{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182df0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Reshape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603d8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae2108e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a04920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"FridgeDetection_data\"\n",
    "splits = [\"train\", \"test\", \"valid\"]\n",
    "\n",
    "def load_data(split):\n",
    "    image_dir = os.path.join(dataset_root, split, \"images\")\n",
    "    label_dir = os.path.join(dataset_root, split, \"labelTxt\")\n",
    "    \n",
    "    images, labels = [], []\n",
    "    for file in os.listdir(image_dir):\n",
    "        if file.lower().endswith((\".jpg\", \".png\")):\n",
    "            img_path = os.path.join(image_dir, file)\n",
    "            label_path = os.path.join(label_dir, os.path.splitext(file)[0] + \".txt\")\n",
    "            \n",
    "            images.append(cv2.imread(img_path))\n",
    "            labels.append(open(label_path).read() if os.path.exists(label_path) else None)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "data = {split: dict(zip([\"images\", \"labels\"], load_data(split))) for split in splits}\n",
    "\n",
    "# Print summary\n",
    "for split in splits:\n",
    "    print(f\"{split.capitalize()}: Loaded {len(data[split]['images'])} images and {len(data[split]['labels'])} labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce810e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_labels(images, labels, title, num_images=10, max_columns=2):\n",
    "    combined = list(zip(images, labels))\n",
    "    random.shuffle(combined)\n",
    "    images, labels = zip(*combined[:num_images])\n",
    "\n",
    "    num_rows = (len(images) + max_columns - 1) // max_columns\n",
    "    fig, axes = plt.subplots(num_rows, max_columns, figsize=(10, 5 * num_rows))\n",
    "    axes = axes.flatten() if num_images > 1 else [axes]\n",
    "\n",
    "    for ax, img, label_text in zip(axes, images, labels):\n",
    "        img = img.copy()\n",
    "        if label_text:\n",
    "            for line in label_text.strip().splitlines():\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 9:\n",
    "                    coords = list(map(int, parts[:8]))\n",
    "                    label = parts[8]\n",
    "                    pts = np.array(coords).reshape((4, 2))\n",
    "                    cv2.polylines(img, [pts], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "                    cv2.putText(img, label, tuple(pts[0]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for ax in axes[len(images):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.subplots_adjust(top=0.92, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_images_with_labels(data['train']['images'], data['train']['labels'], \"Train Set with Labels\")\n",
    "plot_images_with_labels(data['valid']['images'], data['valid']['labels'], \"Valid Set with Labels\")\n",
    "plot_images_with_labels(data['test']['images'], data['test']['labels'], \"Test Set with Labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddbe231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count labels\n",
    "def count_labels(data):\n",
    "    label_counts = Counter()\n",
    "    for split in data:\n",
    "        for label_data in data[split]['labels']:\n",
    "            if label_data:\n",
    "                for line in label_data.splitlines():\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 9:\n",
    "                        label = parts[8]\n",
    "                        label_counts[label] += 1\n",
    "    return label_counts\n",
    "\n",
    "# Count labels across all splits\n",
    "label_counts = count_labels(data)\n",
    "\n",
    "# Print the counts\n",
    "for label, count in label_counts.items():\n",
    "    print(f\"{label}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4da045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of the first image in the training set\n",
    "image_shape = data['train']['images'][0].shape\n",
    "print(f\"Image size: {image_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f8323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data['train']['images']\n",
    "X_val = data['valid']['images']\n",
    "y_train = data['train']['labels']\n",
    "y_val = data['valid']['labels']\n",
    "X_test = data['test']['images']\n",
    "y_test = data['test']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(img):\n",
    "    # Convert to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    # Clip values to ensure they are within the valid range [0, 1] for floats\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "    # Resize image\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    return img\n",
    "\n",
    "# Apply preprocessing to all sets\n",
    "X_train = np.array([resize(img) for img in X_train])\n",
    "X_val = np.array([resize(img) for img in X_val])\n",
    "X_test = np.array([resize(img) for img in X_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5622bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = X_train[0].shape\n",
    "print(f\"Image size: {image_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_labels(labels, original_size, new_size):\n",
    "    resized_labels = []\n",
    "    scale_x = new_size[0] / original_size[0]\n",
    "    scale_y = new_size[1] / original_size[1]\n",
    "    \n",
    "    for label_data in labels:\n",
    "        if label_data:\n",
    "            resized_label_data = []\n",
    "            for line in label_data.splitlines():\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 9:\n",
    "                    x1, y1, x2, y2, x3, y3, x4, y4, label = parts[:9]\n",
    "                    coords = [int(int(p) * scale_x if i % 2 == 0 else int(p) * scale_y) for i, p in enumerate([x1, y1, x2, y2, x3, y3, x4, y4])]\n",
    "                    resized_label_data.append(f\"{coords[0]} {coords[1]} {coords[2]} {coords[3]} {coords[4]} {coords[5]} {coords[6]} {coords[7]} {label}\")\n",
    "            resized_labels.append(\"\\n\".join(resized_label_data))\n",
    "        else:\n",
    "            resized_labels.append(None)\n",
    "    \n",
    "    return resized_labels# Example usage\n",
    "\n",
    "original_size = (640, 640)  # Assuming original images are 640x640\n",
    "new_size = (224, 224)  # Resized images are 224x224\n",
    "\n",
    "# Resize labels for train, validation, and test sets\n",
    "resized_train_labels = resize_labels(y_train, original_size, new_size)\n",
    "resized_val_labels = resize_labels(y_val, original_size, new_size)\n",
    "resized_test_labels = resize_labels(y_test, original_size, new_size)\n",
    "\n",
    "# Print a few examples to verify\n",
    "print(\"Original label:\", y_train[0])\n",
    "print(\"Resized label:\", resized_train_labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a601650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_with_labels(images, labels, title, num_images=10, max_columns=2):\n",
    "    # Shuffle images and labels together\n",
    "    combined = list(zip(images, labels))\n",
    "    random.shuffle(combined)\n",
    "    images, labels = zip(*combined)\n",
    "    \n",
    "    num_rows = (min(num_images, len(images)) + max_columns - 1) // max_columns\n",
    "    plt.figure(figsize=(10, 5 * num_rows))\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):\n",
    "        img = images[i].copy()  # Make a copy of the image to avoid modifying the original image\n",
    "        if labels[i]:\n",
    "            for line in labels[i].splitlines():\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 9:\n",
    "                    # Extract the coordinates and label\n",
    "                    x1, y1, x2, y2, x3, y3, x4, y4, label = parts[:9]\n",
    "                    \n",
    "                    # Convert the coordinates to integers\n",
    "                    x1, y1, x2, y2, x3, y3, x4, y4 = map(int, [x1, y1, x2, y2, x3, y3, x4, y4])\n",
    "                    \n",
    "                    # Draw the label text\n",
    "                    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "                    \n",
    "                    # Draw the bounding box polygon\n",
    "                    cv2.polylines(img, [np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]], np.int32)], \n",
    "                                   isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "                \n",
    "        \n",
    "        # Plot the image\n",
    "        plt.subplot(num_rows, max_columns, i + 1)\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))  # Convert from BGR to RGB for displaying\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    # Set title and show the plot\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot 10 random images from the train set with labels\n",
    "plot_images_with_labels(X_train, resized_train_labels, \"Train Set with Labels\")\n",
    "\n",
    "# Plot 10 random images from the validation set with labels\n",
    "plot_images_with_labels(X_val, resized_val_labels, \"Valid Set with Labels\")\n",
    "\n",
    "y_train = resized_train_labels\n",
    "y_val = resized_val_labels\n",
    "y_test = resized_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess labels into multi-hot encoded format\n",
    "def encode_labels(labels, label_counts):\n",
    "    label_to_index = {label: idx for idx, label in enumerate(label_counts.keys())}\n",
    "    num_classes = len(label_counts)\n",
    "    \n",
    "    encoded_labels = []\n",
    "    for label_data in labels:\n",
    "        multi_hot = np.zeros(num_classes, dtype=np.float32)\n",
    "        if label_data:\n",
    "            for line in label_data.splitlines():\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 9:\n",
    "                    label = parts[8]\n",
    "                    if label in label_to_index:\n",
    "                        multi_hot[label_to_index[label]] = 1.0\n",
    "        encoded_labels.append(multi_hot)\n",
    "    return np.array(encoded_labels)\n",
    "\n",
    "# Apply preprocessing to train, validation, and test labels\n",
    "y_train_encoded = encode_labels(y_train, label_counts)\n",
    "y_val_encoded = encode_labels(y_val, label_counts)\n",
    "y_test_encoded = encode_labels(y_test, label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e64a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train \n",
    "X_val\n",
    "X_test\n",
    "\n",
    "y_train\n",
    "y_val\n",
    "y_test\n",
    "\n",
    "y_train_encoded\n",
    "y_val_encoded\n",
    "y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75599607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d727510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_from_labels(dataset_root, splits=['train', 'valid', 'test']):\n",
    "    classes = set()\n",
    "    for split in splits:\n",
    "        labelTxt_dir = os.path.join(dataset_root, split, \"labelTxt\")\n",
    "        if not os.path.exists(labelTxt_dir):\n",
    "            continue\n",
    "        for label_file in os.listdir(labelTxt_dir):\n",
    "            if not label_file.endswith('.txt'):\n",
    "                continue\n",
    "            label_path = os.path.join(labelTxt_dir, label_file)\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) < 9:\n",
    "                        continue\n",
    "                    class_name = parts[8]\n",
    "                    classes.add(class_name)\n",
    "    return sorted(classes)\n",
    "\n",
    "def polygon_to_yolo(line, img_width, img_height, class_to_id):\n",
    "    parts = line.strip().split()\n",
    "    coords = list(map(int, parts[:8]))  # 8 coords: x1 y1 x2 y2 x3 y3 x4 y4\n",
    "    class_name = parts[8]\n",
    "    xs = coords[0::2]\n",
    "    ys = coords[1::2]\n",
    "    xmin, xmax = min(xs), max(xs)\n",
    "    ymin, ymax = min(ys), max(ys)\n",
    "    x_center = (xmin + xmax) / 2 / img_width\n",
    "    y_center = (ymin + ymax) / 2 / img_height\n",
    "    width = (xmax - xmin) / img_width\n",
    "    height = (ymax - ymin) / img_height\n",
    "    class_id = class_to_id[class_name]\n",
    "    return f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "\n",
    "def convert_labels(dataset_root, split, class_to_id):\n",
    "    images_dir = os.path.join(dataset_root, split, \"images\")\n",
    "    labelTxt_dir = os.path.join(dataset_root, split, \"labelTxt\")\n",
    "    labels_dir = os.path.join(dataset_root, split, \"labels\")\n",
    "\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    for img_file in os.listdir(images_dir):\n",
    "        if not img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "            continue\n",
    "        img_path = os.path.join(images_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: could not read image {img_path}, skipping.\")\n",
    "            continue\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        label_txt_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "        labelTxt_path = os.path.join(labelTxt_dir, label_txt_file)\n",
    "        label_output_path = os.path.join(labels_dir, label_txt_file)\n",
    "\n",
    "        if not os.path.exists(labelTxt_path):\n",
    "            print(f\"Label file not found for {img_file}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        with open(labelTxt_path, 'r') as f_in, open(label_output_path, 'w') as f_out:\n",
    "            for line in f_in:\n",
    "                yolo_line = polygon_to_yolo(line, w, h, class_to_id)\n",
    "                f_out.write(yolo_line + '\\n')\n",
    "\n",
    "def main():\n",
    "    dataset_root = os.path.abspath(\"FridgeDetection_data\")\n",
    "\n",
    "    print(\"Scanning labelTxt files for classes...\")\n",
    "    class_names = get_classes_from_labels(dataset_root)\n",
    "    print(f\"Classes found: {class_names}\")\n",
    "\n",
    "    class_to_id = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "    print(\"Converting labels to YOLO format...\")\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        convert_labels(dataset_root, split, class_to_id)\n",
    "        print(f\"Converted {split} labels.\")\n",
    "\n",
    "    # Create data.yaml file\n",
    "    data_yaml = {\n",
    "        'train': os.path.join(dataset_root, 'train', 'images'),\n",
    "        'val': os.path.join(dataset_root, 'valid', 'images'),\n",
    "        'test': os.path.join(dataset_root, 'test', 'images'),\n",
    "        'nc': len(class_names),\n",
    "        'names': class_names\n",
    "    }\n",
    "\n",
    "    yaml_path = os.path.join(dataset_root, \"data.yaml\")\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(data_yaml, f)\n",
    "\n",
    "    print(f\"data.yaml created at {yaml_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c525734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_root = os.path.abspath(\"FridgeDetection_data\")\n",
    "yaml_path = os.path.join(dataset_root, \"data.yaml\")\n",
    "\n",
    "# Create empty lists to store metrics\n",
    "epochs = []\n",
    "box_losses = []\n",
    "cls_losses = []\n",
    "dfl_losses = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "map50s = []\n",
    "map5095s = []\n",
    "\n",
    "# Load your YOLO model\n",
    "model = YOLO('yolov8n.pt')  # or your custom model path\n",
    "\n",
    "results = model.train(\n",
    "    data='FridgeDetection_data/data.yaml',\n",
    "    epochs=10,\n",
    "    batch=16,\n",
    "    device='0',\n",
    "    project='runs',    # folder to save results\n",
    "    name='exp1',       # experiment subfolder\n",
    "    exist_ok=True      # overwrite if exists\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Now that training is done, check for the results directory\n",
    "runs_dir = os.path.join(\"runs\", \"exp1\")\n",
    "\n",
    "results_csv = os.path.join(runs_dir, \"results.csv\")\n",
    "if not os.path.isfile(results_csv):\n",
    "    raise FileNotFoundError(f\"'{results_csv}' not found. Make sure training has completed successfully.\")\n",
    "\n",
    "df = pd.read_csv(results_csv)\n",
    "\n",
    "# Print columns to debug\n",
    "print(\"Available columns in results.csv:\", df.columns.tolist())\n",
    "\n",
    "# Use correct column names based on what is available\n",
    "# Common YOLOv8 columns: 'epoch', 'train/box_loss', 'train/cls_loss', 'train/dfl_loss', 'metrics/precision(B)', etc.\n",
    "epochs = df['epoch'] + 1 if 'epoch' in df.columns else df.index + 1\n",
    "\n",
    "box_losses = df['train/box_loss'] if 'train/box_loss' in df.columns else None\n",
    "cls_losses = df['train/cls_loss'] if 'train/cls_loss' in df.columns else None\n",
    "dfl_losses = df['train/dfl_loss'] if 'train/dfl_loss' in df.columns else None\n",
    "precisions = df['metrics/precision(B)'] if 'metrics/precision(B)' in df.columns else None\n",
    "recalls = df['metrics/recall(B)'] if 'metrics/recall(B)' in df.columns else None\n",
    "map50s = df['metrics/mAP_0.5(B)'] if 'metrics/mAP_0.5(B)' in df.columns else None\n",
    "map5095s = df['metrics/mAP_0.5:0.95(B)'] if 'metrics/mAP_0.5:0.95(B)' in df.columns else None\n",
    "\n",
    "\n",
    "# Plot metrics after training\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "if box_losses is not None:\n",
    "    plt.plot(epochs, box_losses, label='Box Loss')\n",
    "if cls_losses is not None:\n",
    "    plt.plot(epochs, cls_losses, label='Class Loss')\n",
    "if dfl_losses is not None:\n",
    "    plt.plot(epochs, dfl_losses, label='DFL Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training Losses')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "if precisions is not None:\n",
    "    plt.plot(epochs, precisions, label='Precision')\n",
    "if recalls is not None:\n",
    "    plt.plot(epochs, recalls, label='Recall')\n",
    "if map50s is not None:\n",
    "    plt.plot(epochs, map50s, label='mAP@0.5')\n",
    "if map5095s is not None:\n",
    "    plt.plot(epochs, map5095s, label='mAP@0.5:0.95')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metric')\n",
    "plt.legend()\n",
    "plt.title('Validation Metrics')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Validate the model on the validation set\n",
    "results_val = model.val(data=yaml_path, imgsz=640, batch=16, workers=0, device='0')\n",
    "print(\"Validation results:\", results_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95728fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# runs_root = 'runs'\n",
    "# if os.path.exists(runs_root):\n",
    "#     print(\"Contents of 'runs' folder:\")\n",
    "#     print(os.listdir(runs_root))\n",
    "# else:\n",
    "#     print(\"'runs' folder does not exist.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eecbf84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6889428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "# import os\n",
    "\n",
    "\n",
    "# # Path to the data.yaml file\n",
    "# yaml_path = \"FridgeDetection_data/data.yaml\"  # Path to your data.yaml file\n",
    "\n",
    "# # Test set images folder from the data.yaml (Ensure this matches your YAML file setup)\n",
    "# test_images_path = \"FridgeDetection_data/test/images\"  # Path to your test images\n",
    "\n",
    "# # List all test images\n",
    "# test_images = [os.path.join(test_images_path, img) for img in os.listdir(test_images_path) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# # Run predictions on the test images\n",
    "# for image_path in test_images:\n",
    "#     # Make predictions on each test image\n",
    "#     results = model.predict(image_path, device='cuda:0')  # Run on GPU 0 if available, else use CPU\n",
    "\n",
    "#     # results is a list; iterate through each result\n",
    "#     for result in results:\n",
    "#         # Show predictions on the image\n",
    "#         result.show()  # This will show the image with predicted bounding boxes\n",
    "\n",
    "#         # Optionally save predictions (with bounding boxes) to disk\n",
    "#         result.save()  # Save the images with predictions in the 'runs/detect' folder\n",
    "\n",
    "#         # Optionally print details of the results\n",
    "#         print(f\"Predictions for {image_path}:\")\n",
    "#         print(result.to_df())  # Print bounding box results in a pandas dataframe format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236cd065",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Path to the data.yaml file (if needed)\n",
    "yaml_path = \"FridgeDetection_data/data.yaml\"  # Path to your data.yaml file\n",
    "\n",
    "# Test set images folder from the data.yaml (Ensure this matches your YAML file setup)\n",
    "test_images_path = \"FridgeDetection_data/test/images\"  # Path to your test images\n",
    "\n",
    "# List all test images\n",
    "test_images = [os.path.join(test_images_path, img) for img in os.listdir(test_images_path) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Run predictions on the test images\n",
    "for image_path in test_images:\n",
    "    # Make predictions on each test image\n",
    "    results = model.predict(image_path, device='cuda:0')  # Run on GPU 0 if available, else use CPU\n",
    "    \n",
    "    # results is a list; iterate through each result\n",
    "    for result in results:\n",
    "        # Show predictions on the image\n",
    "        # result.show()  # This will show the image with predicted bounding boxes\n",
    "        \n",
    "        # # Optionally save predictions (with bounding boxes) to disk\n",
    "        # result.save()  # Save the images with predictions in the 'runs/detect' folder\n",
    "\n",
    "        # Optionally print details of the results\n",
    "        print(f\"Predictions for {image_path}:\")\n",
    "        \n",
    "        # Convert to a pandas DataFrame\n",
    "        df = result.to_df()  # Get bounding box results as a pandas DataFrame\n",
    "        \n",
    "        # Display the dataframe in the notebook\n",
    "        display(df)  # This will print the DataFrame in the notebook output\n",
    "        \n",
    "        # This will print the class labels and confidence score for each detected object\n",
    "        print(\"Predicted classes and their confidence scores:\")\n",
    "        if not df.empty and 'name' in df.columns and 'confidence' in df.columns:\n",
    "            display(df[['name', 'confidence']])  # Display only the class and confidence columns\n",
    "        else:\n",
    "            print(\"No detections.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "yaml_path = \"FridgeDetection_data/data.yaml\"  # Path to your data.yaml file\n",
    "\n",
    "test_images_path = \"FridgeDetection_data/test/images\"\n",
    "annotations_path = \"FridgeDetection_data/test/labels\"\n",
    "\n",
    "# List all test images\n",
    "all_test_images = [os.path.join(test_images_path, img) for img in os.listdir(test_images_path) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Select 10 random images\n",
    "test_images = random.sample(all_test_images, min(10, len(all_test_images)))  # Ensure we don‚Äôt exceed the available count\n",
    "\n",
    "\n",
    "def get_ground_truth(image_path):\n",
    "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    gt_file = os.path.join(annotations_path, base_name + '.txt')\n",
    "    if os.path.exists(gt_file):\n",
    "        with open(gt_file, 'r') as f:\n",
    "            gt_data = [line.strip().split() for line in f.readlines()]\n",
    "            return pd.DataFrame(gt_data, columns=['class_id', 'x_center', 'y_center', 'width', 'height'])\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def iou(box1, box2):\n",
    "    x1_min = box1[0] - box1[2] / 2\n",
    "    x1_max = box1[0] + box1[2] / 2\n",
    "    y1_min = box1[1] - box1[3] / 2\n",
    "    y1_max = box1[1] + box1[3] / 2\n",
    "    \n",
    "    x2_min = box2[0] - box2[2] / 2\n",
    "    x2_max = box2[0] + box2[2] / 2\n",
    "    y2_min = box2[1] - box2[3] / 2\n",
    "    y2_max = box2[1] + box2[3] / 2\n",
    "    \n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "    \n",
    "    intersection_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)\n",
    "    box1_area = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    box2_area = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    \n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    return intersection_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Run predictions and evaluation\n",
    "for image_path in test_images:\n",
    "    print(f\"\\nProcessing image: {image_path}\")\n",
    "    results = model.predict(image_path, device='cuda:0')\n",
    "\n",
    "    for result in results:\n",
    "        df_predictions = result.to_df()\n",
    "        if not df_predictions.empty:\n",
    "            print(\"Prediction columns:\", df_predictions.columns.tolist())\n",
    "        df_ground_truth = get_ground_truth(image_path)\n",
    "        if not df_ground_truth.empty:\n",
    "            for col in ['x_center', 'y_center', 'width', 'height']:\n",
    "                df_ground_truth[col] = df_ground_truth[col].astype(float)\n",
    "\n",
    "        if not df_predictions.empty and not df_ground_truth.empty:\n",
    "            print(f\"Comparing predictions with actual for {image_path}:\")\n",
    "            correct_predictions = 0\n",
    "            total_predictions = len(df_predictions)\n",
    "            for _, pred_row in df_predictions.iterrows():\n",
    "                predicted_class = str(pred_row['class'])  # class id is stored as int/float\n",
    "                if 'box' in df_predictions.columns:\n",
    "                    box = pred_row['box']\n",
    "                    if isinstance(box, (list, np.ndarray, tuple)) and len(box) == 4:\n",
    "                        try:\n",
    "                            x1, y1, x2, y2 = map(float, box)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Skipping invalid box data: {box} ({e})\")\n",
    "                            continue\n",
    "                        x_center = (x1 + x2) / 2\n",
    "                        y_center = (y1 + y2) / 2\n",
    "                        width = x2 - x1\n",
    "                        height = y2 - y1\n",
    "                    else:\n",
    "                        print(f\"Invalid box format: {box}\")\n",
    "                        continue\n",
    "                else:\n",
    "                    print(\"No bounding box columns found!\")\n",
    "                    continue\n",
    "\n",
    "                predicted_box = np.array([x_center, y_center, width, height])\n",
    "                predicted_confidence = pred_row['confidence']\n",
    "                matching_gt = df_ground_truth[df_ground_truth['class_id'] == predicted_class]\n",
    "\n",
    "                if not matching_gt.empty:\n",
    "                    gt_box = matching_gt[['x_center', 'y_center', 'width', 'height']].iloc[0].to_numpy()\n",
    "                    iou_score = iou(predicted_box, gt_box)\n",
    "                    if iou_score >= 0.5 and predicted_confidence > 0.5:\n",
    "                        correct_predictions += 1\n",
    "\n",
    "            accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0\n",
    "            print(f\"Prediction accuracy for {image_path}: {accuracy:.2f}%\")\n",
    "        else:\n",
    "            print(\"No detections or ground truth data.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3271d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883d9cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the fixed settings\n",
    "    fixed_params = {\n",
    "        \"data\": \"FridgeDetection_data/data.yaml\",\n",
    "        \"epochs\": 10,  # use fewer epochs for fast tuning\n",
    "        \"imgsz\": 640,\n",
    "        \"device\": \"0\",\n",
    "        \"batch\": 16,\n",
    "        \"workers\": 0\n",
    "    }\n",
    "\n",
    "    # Define the search space\n",
    "    params = {\n",
    "        \"lr0\": trial.suggest_float(\"lr0\", 1e-4, 1e-2, log=True),\n",
    "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True),\n",
    "        \"mosaic\": trial.suggest_float(\"mosaic\", 0.5, 1.0),\n",
    "        \"mixup\": trial.suggest_float(\"mixup\", 0.0, 0.3),\n",
    "        \"hsv_h\": trial.suggest_float(\"hsv_h\", 0.0, 0.05),\n",
    "        \"box\": trial.suggest_float(\"box\", 5.0, 10.0),\n",
    "        \"cls\": trial.suggest_float(\"cls\", 0.1, 1.0),\n",
    "        \"dfl\": trial.suggest_float(\"dfl\", 1.0, 3.0),\n",
    "    }\n",
    "\n",
    "    full_config = {**fixed_params, **params}\n",
    "\n",
    "    # Load model\n",
    "    model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "    # Train model\n",
    "    model.train(**full_config)\n",
    "\n",
    "    # Validate model\n",
    "    results = model.val(data=fixed_params[\"data\"])\n",
    "\n",
    "    # Use mAP@0.5 as the optimization target\n",
    "    map50 = results.box.map50\n",
    "    return map50\n",
    "\n",
    "# Run Optuna optimization\n",
    "def tune_yolo(trials=20):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=trials)\n",
    "\n",
    "    print(\"\\n‚úÖ Best hyperparameters:\")\n",
    "    for k, v in study.best_params.items():\n",
    "        print(f\"{k}: {v:.6f}\")\n",
    "    print(f\"üèÜ Best mAP@0.5: {study.best_value:.4f}\")\n",
    "\n",
    "    return study\n",
    "\n",
    "# Run the tuner\n",
    "study = tune_yolo(trials=10)  # You can increase trials for better results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b7ccc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50c2ead5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
